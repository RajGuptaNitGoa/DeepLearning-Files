{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of deep learning with Keras (a high-level neural networks API in Python), Sequential() is a model type that is used to create a linear stack of layers. The Sequential model is simple and straightforward, where you define one layer at a time, and each layer has exactly one input tensor and one output tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a Model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense: This layer type is a fully connected (dense) layer, where each neuron receives input from all neurons of the previous layer.\n",
    "\n",
    "units=32: This parameter sets the number of neurons in the layer to 32.\n",
    "\n",
    "activation='relu': The Rectified Linear Unit (ReLU) activation function is applied to the output of each neuron, which introduces non-linearity and helps the network learn more complex functions. ReLU returns 0 for any input less than 0 and returns the input for any input greater than or equal to 0.\n",
    "\n",
    "input_dim=30: This parameter specifies the dimension of the input data. The model expects input vectors with 30 features. This parameter is only required for the first layer to define the input shape.\n",
    "\n",
    "\n",
    "units=1: This layer has a single neuron, making it suitable for binary classification tasks where the output is either 0 or 1.\n",
    "\n",
    "activation='sigmoid': The Sigmoid activation function maps the output to a value between 0 and 1. It’s typically used in the output layer for binary classification problems because it can be interpreted as a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = Dense(units=32, activation = 'relu', input_dim = 30)\n",
    "model.add(layer1)\n",
    "model.add(Dense(units=16, activation = 'relu'))\n",
    "model.add(Dense(units=1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizer: optimizer='adam'\n",
    "Purpose: The optimizer is used to update the weights of the neural network to minimize the loss during training.\n",
    "\n",
    "'adam': Adam (Adaptive Moment Estimation) is an advanced optimization algorithm that adjusts the learning rate for each parameter. It combines the advantages of two other popular optimizers:\n",
    "\n",
    "AdaGrad (Adaptive Gradient Algorithm): It adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent parameters.\n",
    "\n",
    "RMSProp (Root Mean Square Propagation): It divides the learning rate by an exponentially decaying average of squared gradients.\n",
    "\n",
    "Adam uses estimates of first and second moments of the gradients to adapt the learning rate, which helps in achieving faster convergence and robust performance. It requires minimal configuration and is well-suited for most problems.\n",
    "\n",
    "\n",
    "2. Loss Function: loss='binary_crossentropy'\n",
    "Purpose: The loss function measures how well the model's predictions match the true labels. It is a key component used by the optimizer to guide the training process.\n",
    "\n",
    "'binary_crossentropy': This loss function is used for binary classification tasks, where the target variable has only two possible outcomes (e.g., 0 or 1). It calculates the cross-entropy loss between the true labels and the predicted probabilities. \n",
    "\n",
    "\n",
    "3. Metrics: metrics=['accuracy']\n",
    "Purpose: Metrics are used to evaluate the performance of the model during training and testing. Unlike the loss, metrics are not used to train the model but to monitor its performance.\n",
    "\n",
    "'accuracy': Accuracy measures the proportion of correctly classified samples out of the total samples. For binary classification, it is calculated as:\n",
    "\n",
    " \n",
    "Example: If the model correctly classifies 90 out of 100 samples, the accuracy is 0.90 or 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_state=0:\n",
    "\n",
    "Purpose: Controls the shuffling applied to the data before applying the split.\n",
    "Value: 0 ensures that the split is reproducible. Using the same random_state value allows you to get the same split every time you run the code.\n",
    "Example: This is important for debugging and comparison, as it ensures that your training and test sets are the same across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "cancer = datasets.load_breast_cancer()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size = 0.2, random_state = 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs=20:\n",
    "\n",
    "Purpose: Specifies the number of times the model will iterate over the entire training dataset.\n",
    "Value: 20 means the model will train for 20 full passes over the training data.\n",
    "Example: If your dataset has 1000 samples and you set epochs=20, the model will make 20 passes through all 1000 samples during training.\n",
    "batch_size=50:\n",
    "\n",
    "Purpose: Defines the number of samples per gradient update (batch).\n",
    "Value: 50 means the model will update its weights after processing 50 samples. This means that during training, the dataset is divided into mini-batches of 50 samples, and the model parameters are updated after each batch.\n",
    "Example: If x_train has 1000 samples and batch_size is 50, the model will divide the data into 20 batches and update weights 20 times per epoch.\n",
    "validation_data=(x_test, y_test):\n",
    "\n",
    "Purpose: Provides the validation dataset to evaluate the model’s performance after each epoch, without using it for training.\n",
    "Content:\n",
    "x_test: Input features for the validation set.\n",
    "y_test: Labels for the validation set.\n",
    "\n",
    "Example: During training, after each epoch, the model will be evaluated on this validation data to monitor its performance and to help in preventing overfitting by observing the loss and metrics on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/20\n",
      "455/455 [==============================] - 0s 82us/step - loss: 0.0593 - acc: 0.9912 - val_loss: 0.0798 - val_acc: 0.9561\n",
      "Epoch 2/20\n",
      "455/455 [==============================] - 0s 111us/step - loss: 0.0575 - acc: 0.9912 - val_loss: 0.0777 - val_acc: 0.9561\n",
      "Epoch 3/20\n",
      "455/455 [==============================] - 0s 155us/step - loss: 0.0561 - acc: 0.9912 - val_loss: 0.0758 - val_acc: 0.9561\n",
      "Epoch 4/20\n",
      "455/455 [==============================] - 0s 112us/step - loss: 0.0540 - acc: 0.9912 - val_loss: 0.0763 - val_acc: 0.9561\n",
      "Epoch 5/20\n",
      "455/455 [==============================] - 0s 122us/step - loss: 0.0529 - acc: 0.9912 - val_loss: 0.0734 - val_acc: 0.9561\n",
      "Epoch 6/20\n",
      "455/455 [==============================] - 0s 197us/step - loss: 0.0516 - acc: 0.9890 - val_loss: 0.0702 - val_acc: 0.9649\n",
      "Epoch 7/20\n",
      "455/455 [==============================] - 0s 138us/step - loss: 0.0500 - acc: 0.9890 - val_loss: 0.0687 - val_acc: 0.9649\n",
      "Epoch 8/20\n",
      "455/455 [==============================] - 0s 95us/step - loss: 0.0485 - acc: 0.9912 - val_loss: 0.0676 - val_acc: 0.9649\n",
      "Epoch 9/20\n",
      "455/455 [==============================] - 0s 149us/step - loss: 0.0474 - acc: 0.9912 - val_loss: 0.0669 - val_acc: 0.9649\n",
      "Epoch 10/20\n",
      "455/455 [==============================] - 0s 183us/step - loss: 0.0465 - acc: 0.9912 - val_loss: 0.0663 - val_acc: 0.9649\n",
      "Epoch 11/20\n",
      "455/455 [==============================] - 0s 121us/step - loss: 0.0450 - acc: 0.9912 - val_loss: 0.0654 - val_acc: 0.9649\n",
      "Epoch 12/20\n",
      "455/455 [==============================] - 0s 175us/step - loss: 0.0439 - acc: 0.9912 - val_loss: 0.0642 - val_acc: 0.9737\n",
      "Epoch 13/20\n",
      "455/455 [==============================] - 0s 270us/step - loss: 0.0430 - acc: 0.9912 - val_loss: 0.0636 - val_acc: 0.9737\n",
      "Epoch 14/20\n",
      "455/455 [==============================] - 0s 141us/step - loss: 0.0422 - acc: 0.9912 - val_loss: 0.0627 - val_acc: 0.9737\n",
      "Epoch 15/20\n",
      "455/455 [==============================] - 0s 140us/step - loss: 0.0413 - acc: 0.9912 - val_loss: 0.0619 - val_acc: 0.9737\n",
      "Epoch 16/20\n",
      "455/455 [==============================] - 0s 135us/step - loss: 0.0408 - acc: 0.9912 - val_loss: 0.0609 - val_acc: 0.9737\n",
      "Epoch 17/20\n",
      "455/455 [==============================] - 0s 131us/step - loss: 0.0394 - acc: 0.9912 - val_loss: 0.0605 - val_acc: 0.9649\n",
      "Epoch 18/20\n",
      "455/455 [==============================] - 0s 159us/step - loss: 0.0385 - acc: 0.9912 - val_loss: 0.0603 - val_acc: 0.9649\n",
      "Epoch 19/20\n",
      "455/455 [==============================] - 0s 115us/step - loss: 0.0379 - acc: 0.9912 - val_loss: 0.0605 - val_acc: 0.9649\n",
      "Epoch 20/20\n",
      "455/455 [==============================] - 0s 94us/step - loss: 0.0381 - acc: 0.9912 - val_loss: 0.0606 - val_acc: 0.9649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a1e4c0e48>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size = 50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 65us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.060566798113940057, 0.96491227651897227]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "score = model.evaluate(x_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
